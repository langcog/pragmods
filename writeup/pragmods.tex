\documentclass[man,noapacite]{apa2}
\usepackage{amsmath}
\usepackage{graphicx}
% \usepackage{booktabs}
\usepackage{apacite2}
% \usepackage{fullpage,rotating}
% \usepackage{pslatex}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage{color}

\newcommand{\red}[1]{\textcolor{red}{#1}}


\title{\vspace{-2ex} Rational speech act models of pragmatic reasoning in reference games}

\fiveauthors{Michael C. Frank}{Andr\'es G\'omez Emilsson}{Benjamin Peloquin}{Noah D. Goodman}{Christopher G. Potts}
\fiveaffiliations{Department of Psychology, Stanford University}{Department of Psychology, Stanford University}{Psychology, Stanford University}{Department of Psychology, Stanford University}{Department of Linguistics, Stanford University}

\shorttitle{Rational speech act models}
\rightheader{Rational speech act models}


\newcommand{\argmax}{\operatornamewithlimits{argmax}}

% EXPERIMENT COUNTER
\newcounter{Experiment}
\setcounter{Experiment}{0}
\newcommand{\expt}[1]{\protect\refstepcounter{Experiment}\arabic{Experiment}\label{#1}}
\newcommand{\exptref}[1]{Experiment\,\ref{#1}}
\newcommand{\exptrefrange}[2]{Experiments\,\ref{#1}--\ref{#2}}
\newcommand{\exptrefnoexpt}[1]{\ref{#1}}



% Thanks to Avery Katko and Paul Mains for assistance in data collection and design for \exptrefrange{exp:seqs-1}{exp:prod-2seq}.
\acknowledgements{\singlespace Thanks to Alex Stiller for work on a previous version of the ``base rate'' experiment, to Roger Levy for valuable discussion and the design of the ``odd man out'' stimulus, and to Ally Kraus for designing the stimuli.  Data from \exptref{exp:levels-level} were presented in \citeA{vogel2014}. We gratefully acknowledge ONR N00014-13-1-0287, NSF \#1456077, and the Merck Family Foundation. Please address correspondence to Michael C. Frank, Department of Psychology, Stanford University, 450 Serra Mall (Jordan Hall), Stanford, CA, 94305, tel: (650) 724-4003, email:{\texttt mcfrank@stanford.edu}.

~\\}


\abstract{Human communication is almost always ambiguous, but it typically takes place in a context where this ambiguity can be resolved. A key part of this process of pragmatic disambiguation comes from reasoning about the possible alternative messages that could have been said in that context. Following previous work, we describe pragmatic inference as a process of recursive reasoning---in which listeners reason about speakers and vice versa---using a ``rational speech act'' (RSA) model. We then systematically test the parameters and design decisions of this model through a series of ten experiments using simple one-shot reference-resolution games (N = 7569). Such games present a valuable and tractable microcosm for studying broader questions about communication in context, and human behavior within them is well-described by the RSA framework.}

\begin{document}

\maketitle

\section{Introduction}

Human communication is astonishingly flexible and efficient. Between two people who know each other well, a single word, look, or gesture can convey volumes \cite{sperber1986,clark1996}. Even two people who barely know one another can rapidly leverage their shared vocabulary to create new, economical ways of communicating about novel situations \cite{brennan1996,clark1991}. These successes are all the more impressive considering the systematic issues of vagueness and ambiguity in natural language \cite{keefe1997,wasow2005}. How do we use such slippery means to produce such concrete results?

\citeA{grice1975} provided critical insight into this problem, describing how listeners reason about speakers' language production goals. By assuming that speakers were attempting to be cooperative in their communicative, listeners could then infer the most likely intended goal that would have given rise to that form, given the current circumstances. This proposal allowed the separation of semantic content---those aspects of meaning that are invariant across contexts---from pragmatic content---those aspects of meaning that rely on contextual inferences about speaker intentions.

Although many subsequent analysts have attempted to refine Grice's original proposal or even to reject substantial elements, the semantics/pragmatics distinction has been critical for progress in understanding language comprehension. Nevertheless, because of the difficulties of formalizing notions like context and social goal inference, pragmatics has often remained a ``wastebasket'' for phenomena that are difficult to explain under formal theories of syntax or semantics \cite{bar-hillel1971}. This dismissal of pragmatics is regrettable because of the importance and richness of pragmatic phenomena. In some substantial sense, what linguists call ``pragmatics'' is what language users experience as the use of language in their everyday interpersonal communication---the reality of how context alters interpretation. Thus, an important goal for research in linguistics and the psychology of language is the development of formal tools for understanding pragmatic inferences and bringing them under experimental control.

In this article, we provide an extended presentation and evaluation of a formal framework for understanding pragmatics, known as the ``rational speech act'' (RSA) framework \cite<originally introduced in>{frank2012,goodman2013}. This framework builds on Grice's initial insight and combines it with tools from Bayesian cognitive modeling \cite{tenenbaum2011}. The result is a set of tools for a quantitative understanding of the kind of social goal inference that Grice initially described. In the remainder of this introduction, we provide a brief survey of previous frameworks for pragmatic reasoning \cite<for further review and discussion, see>{goodman2016}, give an informal introduction to RSA models,  and then summarize the plan for the rest of the article.

\subsection{Modeling pragmatic reasoning as rational action}

Our conception of pragmatic enrichment---how the literal semantics of an utterance becomes strengthened in context by a consideration of the speaker's communicative goals---was initially established by \citeA{grice1975}. But Grice's original formulation of pragmatic inference is typically summarized with reference to the \emph{maxims} he proposed. These maxims, a set of normative guidelines that speakers are assumed to follow (be truthful, informative, perspicuous, and relevant), have been immensely influential. Despite this popularity, the maxims themselves do not figure heavily in most contemporary empirical or theoretical work in linguistics and psycholinguistics \cite<e.g.>{chemla2011,breheny2013}. In fact, they are considered by many theorists to be a dead end as a method for deriving pragmatic phenomena \cite<e.g.>{hirschberg1985,frederking1996}. Indeed, though the general Gricean program has been advanced by a number of influential and important theories, none of these have incorporated the initial set of maxims as central part \cite{levinson2000,sperber1986,clark1996}. For example, \citeA{clark1996} extends pragmatic theorizing into the context of conversations, starting with the general Gricean backdrop of the cooperative principle. And \citeA{sperber1986} construct their theory around a single maxim, that of relevance.

Instead, one lasting contribution of Grice's work has been his construal of language use as a subclass of rational action. Grouping language together with other actions has allowed a set of more general tools to be applied. These tools stem from the theory of rational economic action \cite{von-neumann2007}, and allow an analysis of the costs and benefits of individual linguistic actions relative to one another. \citeA{horn1984} proposed an early version of this kind of analysis (elaborating ideas from \citeNP{zipf1949}) in describing pragmatic phenomena as arising from a conflict between listeners, who want sufficient information from an utterance to be able to grasp its meaning, and speakers, who want to expend the minimal effort in talking. Since this initial work, the rational action perspective has been explored more extensively in several different, and largely non-intersecting literatures.

First, researchers interested in the automatic generation of natural language referring expressions explored a utility-theoretic view of the Gricean framework. \citeA{dale1996} write ``Ultimately... Grice's maxims taken col-
lectively mean `Don't include elements that don't do any-
thing.' Our position is that, under a goal-oriented view
of language generation, there is no need to explicitly
follow such a directive at all; the desired behavior just
falls out of the mechanism.'' This perspective inspired and motivated a tradition of work on systems for creating pragmatically felicitous and practically effective referring expressions \cite<e.g.>{dale1995,reiter2000,viethen2006}. More recently, work in this tradition has begun to connect with the empirical literature on language production \cite{van-deemter2012,van-deemter2012b}.\footnote{While in some cases this viewpoint has been taken to be in conflict with the predictions of RSA models \cite<e.g.>{gatt2013}, we focus here on RSA as a model of listeners only, deferring discussion of the complex issue of how well RSA fits speakers' behavior. See \citeA{goodman2016} for further discussion.}

Second, the general connection to game theory and rational action has been expanded productively in the theoretical linguistic literature. Following early work by \citeA{parikh1991}, the connection to game theory has been developed in analyses of a wide range of pragmatic phenomena \cite{van-rooy2004,benz2005,jager2008b}. In particular, a game-theoretic approach to implicature phenomena can be used to derive models of back-and-forth reasoning (in which listeners reason about speakers and vice versa) \cite{franke2009,jager2008}. These models are deeply related to the RSA model that we present, and in many ways can be viewed as discrete precursors to the model. We return to the connections between game-theoretic models and RSA in the formal presentation of the model, below.

Finally, in a more recent strand of work that has tied together some of this previous research, computational linguists interested in parsing human language production in grounded contexts have explored and expanded on ideas about connections between language production and rational action. \citeA{golland2010} introduced a simple one-step reasoning model in which speakers reason about listeners to produce good referring expressions. And \citeA{vogel2013} attempted to derive the Gricean maxims directly from multi-agent decision theory. These pieces of work share deep formal similarities -- in both their use of probabilistic models and nested reasoning processes -- with the framework we next turn to, the Rational Speech Act framework.

\subsection{Rational Speech Act (RSA) models}

RSA models have their antecedents in work on Bayesian cognitive modeling \cite<for review, see>{tenenbaum2011}. These models are predicated on the idea that the probability calculus can be used to represent uncertainty in an agent's internal representations of the world within structured hypothesis spaces. RSA models particularly build on Bayesian models of social reasoning \cite<e.g.>{baker2009}, which use the same tools of expected utility theory to capture agents' reasoning about others' actions.

Building on this work, \citeA{frank2012} and \citeA{goodman2013} introduced RSA models as a class of probabilistic models that capture the nested, back-and-forth of Gricean reasoning. In particular, listeners are modeled as reasoning about the decision-making -- in terms of linguistic costs and benefits -- of speakers. These speakers themselves reason about listeners. This recursion (listener - speaker - listener - speaker - ...) grounds out in the literal semantics of the utterance itself -- described in the model as a ``literal listener.'' In the simplest form of the model, a listener hears an utterance and considers the goals that would have led a speaker would have uttered it. This model-internal speaker in turn considers the literal interpretation of that message compared with other alternatives that would be congruent with the speaker's goal.

Both initial papers on RSA instantiated a model of this type and then tested the congruence of the predictions of the model with the judgments of human observers. \citeA{frank2012} used one-shot reference games in which participants were asked to reason about what speakers and listeners might say or understand given single-word utterances produced in response to displays of geometric objects. And \citeA{goodman2013} used simple vignettes to ask about classic numerical and quantifier implicatures in the presence of varying knowledge on the part of speakers (e.g., what does ``some of the envelopes'' mean given that the speaker hasn't opened all of them?). Both reports found a tight congruence between participants' aggregate judgments and model predictions.

Since these initial reports, a wide range of work has made use of RSA models and their variants to address a range of topics from non-literal language \cite{kao2014} to ambiguity \cite{lassiter2015} and compositionality \cite{potts2015}. The typical pattern of this literature has been to build a new model variant to address a new phenomenon. While these extensions are important, there has been less work that provides a systematic assessment of the basic RSA model and the reference-game paradigms that have often been used to test them. Here we attempt to address this gap.

\subsection{The current work}

The current work has two interlocking goals. The first goal is empirical. Via a sequence of large-scale, web-based experiments, we provide strong evidence that one-shot reference games provide a flexible and precise tool for studying quantitative patterns of human behavior. The second goal is formal. We provide a more comprehensive presentation of RSA models and show that this framework captures many of the patterns of performance we observed in our experiments, although some ambiguities remain. We use this analysis to highlight areas for future formal investigation. Taken together, this body of work suggests that the RSA model provides a powerful set of tools for studying human pragmatic reasoning in quantitative detail.

Our experiments are listed in Table \ref{tab:expts}; they are broken into three sequences. The first of these (``Preliminaries,'' Section \ref{sec:prelims}) explores our experimental paradigm, one-shot reference games, providing experimental evidence that minor design choices do not account for the pattern of data we observe. The second section (``Priors,'' Section \ref{sec:prior}) tests the role of prior expectations in reference game behavior. The third (``Levels,'' Section \ref{sec:levels}) tests the level of recursion that speakers reason to and provides further data on the relationship between prior and posterior measurements.
% The fourth (``Sequences,'' Section \ref{sec:seqs}) takes a first step towards exploring sequential effects in pragmatic reasoning and whether these can scaffold more deeply referential expressions. The fifth and final section (``Production,'' Section \ref{sec:prod}) discusses speaker behavior in reference games and shows that it is sensitive to the costs of language production.

Our plan is as follows. We first present formal details of the RSA model. We next move to our experimental presentation. We then examine the fit of RSA models to our data. To conclude, we discuss limitations and future directions for RSA modeling, as well implications of this work for the study of pragmatics more broadly.

\begin{table}
\caption{\label{tab:expts} Outline of the experiments reported here.}
\begin{tabular}{cllllll}
\hline
Expt. \# & Sequence & Experiment & $N_{total}$ & $N_{include}$ & Summary \\
\hline
\expt{exp:prelims-dv} & Prelims & Dependent variable & 689 & 554 & Forced choice yields best DV \\
\expt{exp:prelims-mc} & & Manipulation check & 580 & 513 & Modest increase in inference for MC \\
\expt{exp:prelims-frame} & & Linguistic frame & 100  & 89 & No difference\\
\expt{exp:prior-frame} & Prior & Elicitation frame & 200 & 175 & No difference \\
\expt{exp:prior-baserate} &  & Base rate & 800 & 488 & Base rate affects inference \\
\expt{exp:prior-valence} &  & Linguistic framing & 550 & 502 & Linguistic valence affects inference\\
\expt{exp:prior-color} &  & Perceptual salience & 300 & 267 & Perceptual salience affects inference \\
\expt{exp:levels-level} & Levels & Level of inference & 416 & 362 & Level 2 difficult for participants \\
% \expt{exp:levels-prior} &    & Levels prior & & CHECK  & \\
\expt{exp:levels-twins}  &    & Twins & 220 & 194  & Few non-literal readings\\
\expt{exp:levels-oddman} &    & Oddman & 300 & 270  & Few non-literal readings\\
% \expt{exp:levels-twinsprior} &    & Twins prior & & CHECK \\
% \expt{exp:levels-oddmanprior}&    & Oddman prior & & CHECK \\
% \expt{exp:levels-size} &  & Distractors & 1750 & 1368 & Model captures matrix layout\\
% \expt{exp:size-distsprior} &  & Distractors prior & TODO & & \\
% \expt{exp:seqs-1} & Sequences & Level 1 & 200 & 191 & Limited sequential effect, no transfer \\
% \expt{exp:seqs-1x3} & & Level 1 x3 & 200 & 193 & No repetion effects \\
% \expt{exp:seqs-2} & & Level 2 & 100 & 93 & Strong sequence effect for L2 \\
% \expt{exp:prod-1} & Production & Level 1 & 450 & 383 & Cost affects overspecification\\
% \expt{exp:prod-1seq} & & Level 1 sequential & 453 & 394 & Production increases L1 inference\\
% \expt{exp:prod-2seq} & & Level 2 sequential & 450 & 389 & Production doesn't increase L2 inference\\
\hline
\end{tabular}
\end{table}


\section{Formal Framework} \label{sec:models-intro}

In this section, we describe formal details of the ``rational speech act'' model. As described above, this model has been presented previously \cite{frank2012,goodman2013}. Our goal here is to provide a more comprehensive formal presentation. This presentation allows us to highlight choice-points in the model that we assess below; in addition, it illuminates parallels and differences with other formal models in this space.
% . (specific comparisons are given in Appendix \ref{app:equivalences}).

% We introduce a notation for signaling games and other recursive reasoning problems \cite{golland2010,franke2012,frank2012,goodman2013}. This notation system allows us to define a set of recursive models; we show that a set of recent systems for pragmatic reasoning can be written within this system. As a consequence, they are equivalent to one another modulo three design decisions:


\subsection{Preliminaries}

A reference game under our definition is a game in which a speaker $S$ and listener $L$ collaborate in a context $C$ to identify a particular object in the context, known as the speaker's intended referent $r_S \in C$. The game has two parts. First the speaker chooses an utterance $w$ based on vocabulary $V$; this process can be as simple as selection from a list or as complex as generation from a grammar. Next the listener guesses a referent $r_L \in C$ after hearing $w$. The game is won if $r_S=r_L$. Although these game-theoretic foundations of RSA allow for definition of more complex payoff schemes (as in e.g., \citeNP{franke2009}), here we assume the simplest possible payoff, which is positive if the game is won and zero otherwise.

We assume that the world consists of a set of objects, some subset of which are present in $C$. There is a distribution $\sigma$ over the objects ${o_1 ... o_n} \in C$, which is mutually known to both speaker and hearer. This distribution picks out those objects in the context which are more or less likely to be talked about, either because of their intrinsic perceptual or conceptual noteworthiness, or because of some prior history between speaker and listener (e.g. one object having been talked about previously). Although in previous work we described it as a ``contextual salience'' distribution, we now refer to this distribution as the ``prior'' to avoid bias in our interpretation.

There is also a mutually-known semantics for the vocabulary of possible words $w$ that a speaker can send. Although in principle these words could be composed (see \citeNP{potts2015} for an example of this approach), here we examine only single words. Each word can be described as a Kronecker $\delta$ function that applies to objects and returns 1 if the message is true of that object, 0 otherwise. When applied to a context, a word specifies a uniform distribution over those objects of which it is true.

\subsection{The model}

We define the RSA model in terms of sub-agents, listeners $L$ and speakers $S$. Their goals are to reason about one another so that they are able to transmit information efficiently. $L$s reason abut what word $S$s would have said to describe a particular referent; $S$s reason about what interpretation $L$s would give to a particular message. Each agent uses Bayesian inference to reason about the other's likely actions.

So, beginning our recursion, we can define:

\begin{equation}
  \begin{array}{r@{}l}
    \label{eq:agents}
    P_{L_0}(r_S \mid w, C) & \propto \begin{cases} 1 &\mbox{if } \delta_w(r_s) = 1 \\
0 & \mbox{otherwise.} \end{cases} \\
    P_{S_n}(w \mid r, C) & \propto P_{L_n-1} (r_S \mid w, C)  \\
    P_{L_n}(r_S \mid w, C) & \propto P_{S_n} (w \mid r_S, C)\\
  \end{array}
\end{equation}

The two agents are defined recursively and so individual probabilities are undefined unless the recursion ends.  Agent $L_0$, the ``literal listener,'' grounds the recursion by choosing an interpretation uniformly between available referents that are consistent with $w$. So then $L_1$ reasons about $S_1$, who in turn reasons about $L_0$. But $L_1$ and $S_1$ are not special. By analogy we can define $L_n$, a listener whose inferences reflect $n$ full cycles of listener-speaker recursion. Clearly the level of recursion $n$ is an important parameter, and it is one we discuss below in considerable depth.

We then define a top-level agent for the purposes of decision-making, $L$:

\begin{equation}
P_L (r_s \mid w, C) \propto P_{L_n} (r_s \mid w, C) P(r_s)
\end{equation}

\noindent where $P(r_S)$ is the prior distribution over referents $\sigma$, which we discuss extensively below. In principle, we could also add a prior on words, $P(w)$, but for simplicity here we assume that $P(w) \propto 1$ and do not discuss it further.

\subsection{Utility-theoretic definition}

An alternative definition of our model can be posed in terms of rational action based on speakers' utilities, following the game-theoretic definition above. Consider a speaker who weighs a message $w$ in terms of its informational benefit $I(w)$ and cost $D(w)$:

\begin{equation}
U(w; r_S; D) = I(w; C) - D(w)
\end{equation}

\noindent The speaker should then choose rationally between messages as a function of a choice rule, e.g.:

\begin{equation}
P_S(w \mid r_S, C) \propto e^{-\alpha U(w;r_S; C)}
\end{equation}

\noindent where $\alpha$ is a ``greed'' parameter; if $\alpha=0$, choices are random, as $\alpha \rightarrow \infty$, she always chooses the option with greater utility.

We define informational benefit with respect to the recursively lower listener's surprisal, such that the speaker's utility decreases as the listener (at the level they are assuming, namely $n-1$) has more uncertainty: $I(w; C) = -(-log(L_{n-1}))$. If we assume that cost is constant, that $\alpha=1$, and $n=1$, then the log in surprisal and the exponent in the choice rule cancel, as in the the derivation in \citeA{frank2012}.
% We follow that derivation and do not consider cost or greed parameters, though we briefly return to them in the discussion of our modeling results.

\subsection{Matrix definition}

This probabilistic notation emphasizes individual interpretation probabilities; here we briefly describe how these models can be applied to entire signaling game matrices. This way of writing the models also highlights some of the similarities to iterated best response models \cite{jager2010}. Write a signaling game is as a binary context matrix $M$ with indices $w$ and $o$ corresponding to words and objects. If $M_{w,o} = 1$, then that word can be named with that object ($w(o) = 1$).

Now define our listener and speaker agents as two functions over signaling game matrices. (As above, for simplicity we consider the case where there are no costs and $\alpha=1$). The first function, $L(x)$, is the listener function; for a particular object word pair, it returns the probability of that object, given the word.

\begin{equation}
L(x_{w,o}) = \frac{x_{w,o}}{\displaystyle\sum_{o' \in C} x_{w,o'} }
\end{equation}

\noindent Applying $L$ to each element of matrix $M$ results in the literal listener $L_0$.

$S(x)$ is then the speaker function, which captures the intuition that the speaker chooses the best word to describe a particular object (from those that are available in the vocabulary). $S(x)$ takes an object-word pair from the matrix and returns the probability of speaking this word, normalized over the other possible words:

\begin{equation}
S(x_{w,o}) = \frac{x_{w,o}}{\displaystyle \sum_{w' \in V(C)} x_{w',o}}
\end{equation}

So now, if we successively apply these functions to matrix $M$, we can define agents with the same recursive depth as in the description above. For example, $L(S(L(M)))$ is equivalent to the $L_1$ agent above. In essence, repeated applications of the $L$ and $S$ functions is equivalent to iterated renormalization, first by columns and then by rows.

\subsection{Worked example}

\begin{figure}[t]
  \centering
  \includegraphics[width=4in]{figures/hatglasses.pdf}
  \caption{\label{fig:ex} An example stimulus item showing our canonical inferential context. The prompt in this case would be ``glasses,'' and the pragmatic target item would be the face with glasses but not a hat (the logical target item would be the face with a hat and glasses). In all experiments reported here, position and identity of all features is randomized across displays; the target was not always the face with glasses nor was it always positioned in the middle.}
\end{figure}

We work through an example computation on the stimulus shown in Figure \ref{fig:ex}. The object by feature matrix $M$ is

\begin{equation}
M = \left[
    \begin{array}{ccc}
      0 & 0 & 1 \\
      0 & 1 & 1\\
    \end{array}
  \right]
\end{equation}

\noindent where the two rows are the messages ``hat'' and ``glasses'' respectively, and the columns correspond to the three faces. So then


\begin{equation}
L(M) = \left[
    \begin{array}{ccc}
      0 & 0 & 1 \\
      0 & .5 & .5\\
    \end{array}
  \right]
\end{equation}

and

\begin{equation}
S(L(M)) = \left[
    \begin{array}{ccc}
      0 & 0 & .66 \\
      0 & 1 & .33\\
    \end{array}
  \right]
\end{equation}

and then,


\begin{equation}
L(S(L(M))) = \left[
    \begin{array}{ccc}
      0 & 0 & 1 \\
      0 & .75 & .25\\
    \end{array}
  \right]
\end{equation}

\noindent Thus, at $L_1$, the message ``glasses'' refers to the face with only glasses.

\subsection{Relationship to other models}

As reviewed above, a wide range of models in many different traditions have explored similar ideas to those in RSA. Here we highlight a few formal connections that are more apparent after having worked through the formal definition of RSA.

In a seminal early paper, \citeA{rosenberg1964} studied simple communication games much like the ones we study here. They model speakers and listeners as non-recursive agents who nevertheless make symmetric choices using a \citeA{luce1963} choice rule.

In a study of referring-expression production, \citeA{golland2010} describe a speaker-centric model in which an agent like $S(M)$ is the ``reflex speaker'' (producing true messages with equal probability) and $S(L(M))$ is called the ``reasoned speaker.''

\citeA{jager2010} describes an iterated best response (IBR) model in which each agent takes the highest probability alternative, e.g.

\begin{equation}
L(x_{w,o}) = \begin{cases}
1 &\mbox{if } x_{w,o} = \max_{o' \in C}{x_{w,o'}}  \\
0 &\mbox{otherwise}
\end{cases}
\end{equation}

\noindent This max operation can lead to a number of undesirable results such as ties or rows/columns with no non-zero elements; the model thus includes some ad-hoc procedures for dealing with these cases. Otherwise, RSA and the IBR model are quite similar in spirit, although RSA does not produce discrete results.

\section{General Experimental Methods}

This section describes the methods used in the experiments reported below. Our goal was to create a general method for measuring pragmatic inferences in simple reference games. Our taking-off point is two previous studies in which simple feature-based displays allowed measurement of pragmatic reasoning in grounded contexts \cite{frank2012,stiller2014}. In what follows we describe some of the general features of these displays and the experiments that use them.
% In the experiments that follow we attempt to demonstrate that these signaling games provide a useful tool for measuring pragmatic reasoning.

\subsection{Participants}

One challenge of pragmatic communication experiments is that repeated communication within a signaling game is very likely to influence responding \cite<e.g.,>{brennan1996}. For this reason, we adopted a massively between-subjects approach, where each participant answered exactly one relevant question.

We adopted a general standard of 50 independent participants per cell, based on the tradeoff between cost and the desired precision of measurements. With samples of N=50 participants making binary decisions, we could assume 95\% confidence intervals with width .24 at their widest; doubling the sample size to N=100 per cell would only reduce width to .18. While not every experiment reflects this precise standard due to idiosyncrasies of recruitment exclusion, we have tried to maintain approximately this standard throughout.

All of the experiments described here were run on Amazon's Mechanical Turk crowdsourcing service, between Fall 2013 and Spring of 2015. In general, each experiment was run as an independent human intelligence task (HIT); a few were posted as multiple hits for convenience or due to experimenter error. In all cases, we remove duplicated workers from the samples, so that data in each experiment represent a set of unique judgments by distinct participants.

In addition to excluding duplicated participants, we also excluded participants who failed manipulation checks (see below). Table \ref{tab:expts} gives details of participants for each experiment.

\subsection{Stimuli}

We created a set of six base domains that had features that could easily be added independently: faces (pictured in Figure \ref{fig:ex}), boats, pizzas, sundaes, snowmen, and christmas trees. We created slightly different versions of each base so that they would appear to be unique (e.g., by varying the proportions or color tone of the face). We then were able to add features to each of these programmatically (with most experiments using two features but some using three). Faces were supplemented with hats, glasses, and mustaches; boats had motors, sails, and cabins; pizzas had olives, peppers, and mushrooms; sundaes had whipped cream, chocolate, and cherries on top; snowmen had mittens, hats, and scarves; and christmas trees had lights, ornaments, and stars on top.

\subsection{Procedure}

Participants viewed the experiment within a browser window. The first screen of the experiment presented a basic description of the paradigm and asked for informed consent. The second screen of the experiment presented the interlocutor, Bob (a cartoon picture of a man), and noted that he liked to do activities with the base item (e.g., visit friends or sail boats). In experiments with familiarization stimuli (e.g., \exptref{exp:prior-baserate}), nine familiarization images were presented on this screen.

The third screen was the key screen: it presented the experimental stimulus (a set of base items augmented with features, representing the signaling game of interest) at the top of the screen. Below each stimulus a letter was displayed. From left to right: A, B and C. In all experiments except for \exptref{exp:prelims-mc}, two manipulation check questions were asked directly below the display using text entry boxes (e.g. ``how many boats have cabins?''). Below this was the prompt, e.g. ``Bob can only say one word to communicate with you and he says: {\it glasses}. Click below on the option that represents the friend that you think Bob is talking about.'' Below this was a set of buttons labeled A, B and C for the participant to indicate which of the three options they thought the speaker was referring to. A final screen asked participants the following: ``Who did you meet in this survey?'',  ``What was this survey about?'' and ``Any other comments for us?'' Optionally, participants could also provide their age and gender, but finishing the experiment was not contingent on doing this.

Note that in the first set of experiments, we manipulate a number of these experimental choices, including the dependent variable, the use of the manipulation check, and the linguistic framing of Bob's utterance. Our description here reflects the defaults used in the majority of the experiments we report.



% Minor stuff:

% Prelims measures has four items

% Size and sequence have no manipulation check

\section{Methodological preliminaries}
\label{sec:prelims}

Our first set of experiments, \exptrefrange{exp:prelims-dv}{exp:prelims-frame}, establish the simple reference games in Figure \ref{fig:ex} as a viable method, testing the replicability of judgments in this paradigm and examining particular experimental decisions.

\begin{figure}[t]
  \centering
  \includegraphics[width=6in]{../plots/1-prelims-dv.pdf}
  \caption{\label{fig:prelims-dv} Data from \exptref{exp:prelims-dv}. Each panel shows results from a different dependent variable (normalized for simplicity into the interval [0,1]. The three columns show results for the foil (e.g., face with nothing), logical (e.g., face with hat and glasses), and pragmatic (face with only glasses) targets. Error bars show 95\% confidence intervals, computed by non-parametric bootstrap.}
\end{figure}

\exptref{exp:prelims-dv} explored the use of different dependent variables. We considered a betting measure, in which participants were instructed to allocate \$100 across the three targets, as in \citeA{frank2012}; a 7-point Likert scale, as in \citeA{goodman2013}; and a simple three-alternative forced choice measure.\footnote{As this experiment was one of our first, we used only four of our six stimulus items: faces, boats, snowmen, and sundaes.} Figure \ref{fig:prelims-dv} shows results from each. With all three dependent variables, the pragmatic target was chosen more than the logical target, but this result was strongest for the forced choice, with 79\% of participants choosing the pragmatic target. Both the Likert and betting measures afforded the possibility of ``hedging'' by allocating equal bets or ratings to the pragmatic and logical targets. Conservative participants took advantage of this possibility very frequently, betting equal amounts on the logical and pragmatic targets 43\% of the time and using equal Likert ratings 46\% of the time. In contrast, the forced-choice dependent variable did not allow this kind of hedging; thus, we adopted it in our further experiments.

\exptref{exp:prelims-mc} was designed to ensure that the presence of the manipulation check---asking participants to count how many of each feature was present---did not induce a task demand that changed the magnitude of pragmatic responding. We saw 83\% pragmatic responding in the manipulation check condition and 77\% pragmatic responding in a matched condition with no manipulation check. Because of the high power of this experiment ($N_{include}$ = 513), the difference between conditions was statistically significant ($\chi^2(2) = 6.97,~p = .03$). Nevertheless, the modest (6\%) difference between conditions suggests that the manipulation check does not \emph{create} the pragmatic effect, though it may heighten participants' attentions to the different distributions of the two features, leading to slightly more pragmatic responding. We continue to use the manipulation check as an exclusion criterion in further experiments.

\exptref{exp:prelims-frame} was designed to test the particular linguistic framing we used. In particular, we contrasted the presentation of the target word (e.g. ``glasses'') as part of a phrase, ``Bob says: 'My friend has glasses.'~'' and a presentation of the target word with the framing that the speaker can only say a single word (described above in the General Methods). The ``one word'' framing produced 80\% pragmatic responses, while the ``My friend has glasses'' framing produced 82\% pragmatic responses. These frames did not differ significantly from one another in the distribution of responses they produced ($\chi^2(2) = 2.54,~p = .28$). Except where noted below, we adopt the one-word framing.

In sum, these findings suggest that aspects of the experimental presentation and dependent variable have some effects on the magnitude of the pragmatic effect we observed. Nevertheless, the existence of the effect and its magnitude were quite robust to these variations.

\section{Measuring and manipulating prior expectations}
\label{sec:prior}

Our second set of experiments, \exptrefrange{exp:prior-frame}{exp:prior-color}, examine the role of prior expectations---broadly construed---in reference resolution through the kinds of reference games introduced above. These experiments serve two goals. First, they create a set of quantitative measurements of prior expectations combined with listener inferences; these measurements can be used for model comparison and assessment, a topic that we return to in Section \ref{sec:modelcomp}. Second, they allow causal inferences about the role of the prior in participants' pragmatic inferences. While \citeA{frank2012} \emph{measured} prior expectations and showed that they improved model fit, that work did not \emph{manipulate} prior expectations, so it was in principle possible that improvements in model fit did not result from a causal role played by prior expectations. We address this issue in the studies below. We begin by comparing methods for eliciting prior expectations (\exptref{exp:prior-frame}). We then investigate three ways of manipulating prior expectations: via base-rates (\exptref{exp:prior-baserate}), via linguistic valence (\exptref{exp:prior-valence}), and via perceptual salience (\exptref{exp:prior-color}).

It is not immediately clear what the best way is to measure prior expectations for purposes of communication. One particular conceptual issue seems important, though: does the term $p(r_s)$ refer to a prior over \emph{reference}, that is, over things that a speaker would talk about? Or does it instead represent a prior over \emph{actions}, that is, over the things that a speaker would do? This is a fairly deep philosophical issue; but it also has important empirical consequences for our current project. If these two kinds of priors differ substantially, then our estimates of $p(r_S)$ might lead to incorrect conclusions. In particular, \citeA{frank2012} introduced a method in which priors were measured identically to listener judgements, with the exception that participants in the prior measurement condition were not given any linguistic information. They were told that the speaker could utter one word to signal their target referent, but that they (the listener) hadn't heard it. This method yielded reliable measurements, but presupposed that the prior was over reference, rather than action.

\begin{figure}[t]
  \centering
  \includegraphics[width=5in]{../plots/2-prior-frame.pdf}
  \caption{\label{fig:prior-frame} Data from \exptref{exp:prior-frame}. Colors indicate different methods for eliciting prior expectations.}
\end{figure}

In \exptref{exp:prior-frame}, we compared prior elicitation methods. We presented participants with the same canonical display we had used in the prior experiments, but asked them one of two prior questions. The reference prior method was based on \citeA{frank2012}, where the participant was told that ``Bob can say one word'' but the word was presented as ``mumblemumble (you didn't hear what he said).'' The action prior method consisted of simply asking, e.g. ``Which friend do you think Bob will visit next?'' The distribution of responses did not differ between the two questions ($\chi^2(2) = 3.45,~p = .18$, Figure \ref{fig:prior-frame}). Overall, participants showed a tendency to choose the logical target (e.g., face with both hat and glasses) most, the foil at intermediate rates, and the pragmatic target relatively less. While this experiment is not decisive regarding the underlying philosophical issue of what kinds of expectations the prior actually tracks, we put aside this issue for the time being and adopt the mumble prior elicitation method for subsequent experiments (as the choice does not appear critical for our purposes).

\begin{figure}[t]
  \centering
  \includegraphics[width=5in]{../plots/2-prior-baserates.pdf}
  \caption{\label{fig:prior-baserate} Data from \exptref{exp:prior-baserate} from prior elicitation and inference conditions. Horizontal axis shows the proportion of familiarization trials that showed the target.}
\end{figure}

In \exptref{exp:prior-baserate}, we attempted to manipulate participants' prior expectations about reference via a manipulation of the base rate of the interlocutor's actions.\footnote{This experiment is conceptually similar to a base-rate manipulation reported in \citeA{stiller2011}. Note however that the manipulation in that experiment uses a different display, one more similar to those used in \exptref{exp:levels-level}.} Prior to showing the target inference, we exposed participants to evidence about the habits of the interlocutor (Bob). The familiarization screen in this experiment stated (for example, in the case of the face stimulus) that Bob visited a friend every week; it then invited the participant to click on nine boxes to uncover the nine friends that Bob had visited most recently. Across four between-subjects base rate conditions, we manipulated how many of these boxes contained the pragmatic target (e.g., the face with glasses and no hat). One of the boxes always contained the foil (no glasses or hat) and another contained the logical target (hat and glasses). Then the other boxes contained either the pragmatic or the logical target. The four conditions were created such that 1/9, 3/9, 5/9, and 7/9 boxes showed the pragmatic target.

Figure \ref{fig:prior-baserate} shows the results of this manipulation.\footnote{This experiment had unusually high rates of exclusion due to participants' confusion about whether they should report  familiarization frequencies for the manipulation check. We maintain our strict inclusion criterion here but note that the results are largely unchanged if we include these participants.}  The base rate had a strong effect on the prior elicitation, but it also boosted levels of pragmatic inferences. To quantify these effects, we used a logistic regression model (no hierarchical model was warranted because judgments were from independent participants). This model showed highly significant effects of base rate ($\beta = .27,~p = .004$) and condition  (with prior as the dummy-coded predictor, $\beta = -.57,~p < .0001$), as well as a marginal interaction of the two  ($\beta = .29,~p = .06$). Critically, the main effect of base rate remained reliable in a similar logistic regression for just the inference trials ($\beta = .28,~p = .0001$), indicating a highly reliable (and graded) effect of the base-rate manipulation on the strength of the pragmatic inference.


\begin{figure}[t]
  \centering
  \includegraphics[width=4in]{../plots/2-prior-valence.pdf}
  \caption{\label{fig:prior-valence} Data from \exptref{exp:prior-valence} in the inference conditions.}
\end{figure}

Our next experiment, \exptref{exp:prior-valence}, investigated the effects of linguistic manipulations on participants' priors and their resulting inferences. In this experiment, we framed judgments as being about determining Bob's \emph{favorite} or \emph{least favorite} item.\footnote{This experiment was conducted chronologically earlier in the sequence and had four rather than six experimental items: faces, boats, pizzas, and snowmen.} While the manipulation was crude, we reasoned that, all else being equal, Bob's favorite item would likely have more features, while his least favorite would likely have fewer. Prior measurements supported this conclusion: The logical option, which had the most features, was chosen as ``favorite'' 70\% of the time, while the distractor option, which had zero features, was chosen as ``least favorite'' 77\% of the time. Pragmatic inferences reflected these changing expectations, with participants far less likely to choose the pragmatic target in the inference condition with a ``favorite'' frame than with a ``least favorite'' frame (Figure \ref{fig:prior-valence}).

\begin{figure}[t]
  \centering
  \includegraphics[width=4in]{../plots/2-prior-color.pdf}
  \caption{\label{fig:prior-color} Data from \exptref{exp:prior-color} in the inference conditions.}
\end{figure}

Our final experiment in this sequence, \exptref{exp:prior-color}, attempted to manipulate prior expectations about reference by changing the salience of the different referents. In particular, we presented all but one of the images in grayscale, varying which of the images (pragmatic target, logical target, or foil) was shown in color.\footnote{To ensure that participants still made the inference more generally, we included a condition where none of the referents was shown in color, notated by ``none.''} This manipulation had a strong effect on both prior expectations and pragmatic inferences. In particular, when the logical target was shown in color, inferences to the pragmatic target dropped substantially (Figure \ref{fig:prior-color}), presumably because the color either drew attention to the logical target or signaled to participants that their attention \emph{should be} drawn to the logical target. \red{TODO: stats}

In sum, though the type of manipulation varies widely across them, Experiments \exptrefrange{exp:prior-baserate}{exp:prior-color} together show strong evidence that many information sources can affect prior expectations about reference. In Section \ref{sec:modelcomp}, we return to these data and test the stronger hypothesis that variation in inference levels in these three experiments can be accounted for by variation in prior expectations.


\section{Levels of recursion and limits on human reasoning}
\label{sec:levels}

In our next set of experiments, \exptrefrange{exp:levels-level}{exp:levels-oddman}, we probed limits on the kind of inferences we could measure in our reference game paradigm. In all of these experiments, we also conducted parallel experiments measuring prior expectations using the methods described in Section \ref{sec:prior}, but we largely omit discussion of these data until Section \ref{sec:modelcomp}.


 \begin{figure}[t]
  \centering
  \includegraphics[width=4in]{../plots/3-levels-levels.pdf}\\
  A) \includegraphics[width=3in]{figures/hatglasses.pdf}\\
  B) \includegraphics[width=3in]{figures/levels-levels-stim.pdf}
  \caption{\label{fig:levels-level} Data from \exptref{exp:levels-level}, plotted by display (A being simple, B being complex) and inference level (see text).}
\end{figure}


In our first experiment, \exptref{exp:levels-level}, we attempted to measure patterns of inference in more complex reference games. Following \citeA{stiller2011} and \citeA{degen2012}, we created a matrix that required a deeper level of reasoning than our previous experiments. In particular, we compared our standard reference game (shown again for reference in Figure \ref{fig:levels-level}A) with a more complex game (Figure \ref{fig:levels-level}B):


\begin{equation}
\left[
    \begin{array}{ccc}
      0 & 0 & 1 \\
      0 & 1 & 1\\
      1 & 1 & 0
    \end{array}
  \right]
\end{equation}

\noindent In RSA-style models, the level of recursion $n$ describes the number of iterations of speaker-listener computation that are performed. Here we impose this notation on individual inferences and whole matrices. We refer to a ``level 1'' inference as one that an RSA agent with $n=1$ can solve (e.g., the designated target has the highest probability of the possible choices). By analogy, then, a ``level 1'' matrix stimulus is one for which all possible inferences can be answered correctly at greater than chance levels by an RSA agent with $n=1$.

In \exptref{exp:levels-level}, we used the stimulus in Figure \ref{fig:levels-level}A to measure inferences about the pragmatic target (as above, a level 1 inference) and the target with the unique feature (e.g. choosing the hat with the word ``hat''; a level 0 inference). We also used the stimuluis in Figure \ref{fig:levels-level}B to measure a level 1 pragmatic inference (the target for this inference was the face with a mustache but no glasses, for the utterance ``mustache''). The main contribution of this experiment, however, was our test of a level 2 inference (``glasses,'' with the presumptive target the face with glasses and mustache, not glasses and hat). This inference depends on having reasoned that while both of the targets have another possible descriptor, for one of those targets, the second descriptor is unique, whereas for the other the second descriptor is also non-unique.

As shown in Figure \ref{fig:levels-level}, judgments in the Level 1 inference remained very close to 75\%, regardless of display (the level observed across many of our other experiments). Level 0 inferences were of course at ceiling. In contrast, Level 2 inferences were at chance (53\%). The prior for this target was lower than the prior for the logical distractor image, however (23\% vs 39\%). Thus, it may be the case that participants make this inference but it is partially or fully cancelled out by an expectation against it (see Figure 1 of Frank \& Goodman, 2012, for a potential example of this kind of cancelation).

 \begin{figure}[t]
  \centering
  \includegraphics[width=4in]{figures/levels-twins-stim.pdf}
  \includegraphics[width=4in]{../plots/3-levels-twins.pdf}
  \caption{\label{fig:levels-twins} Data from \exptref{exp:levels-twins}, along with the display used for this experiment.}
\end{figure}

\exptref{exp:levels-twins} further considered the scope of the inferences that participants would make by examining displays like the one shown in Figure \ref{fig:levels-twins}, top:

\begin{equation}
\left[
    \begin{array}{ccc}
      0 & 1 & 1 \\
      1 & 0 & 0\\
      1 & 1 & 1
    \end{array}
  \right]
\end{equation}

\noindent These displays had a uniform feature and another feature that was shared by two of the three objects. Intuitively, naming the unique feature (``glasses'') should reference the object with it. But the predictions for the other features are perhaps less clear. Should the uniform feature also resolve to the unique object (e.g. ``mustache'' means {\sc mustache+glasses})? And should the duplicated feature resolve to the duplicated objects, or to the non-duplicated object, violating the literal semantics?

Findings, shown in Figure \ref{fig:levels-oddman}, suggest that referencing the twin feature ({\sc hat}) led to a high degree of choice of one of the duplicated referents; choice of the uniform feature ({\sc mustache}) led to more choices of the unique object. Inferences about ``mustache,'' the uniform feature'' led to a standard level 1 implicature; inferences about the ``twin'' feature provided little evidence that participants violated the literal semantics of the ambiguous predicate.

 \begin{figure}[t]
  \centering
  \includegraphics[width=4in]{figures/levels-oddman-stim.pdf}
  \includegraphics[width=4in]{../plots/3-levels-oddman.pdf}

  \caption{\label{fig:levels-oddman} Data from \exptref{exp:levels-oddman}, along with the display used for this experiment.}
\end{figure}

\exptref{exp:levels-oddman} further considered whether participants would reach communicative equilibria that were at odds with those implied by the literal semantics of the words the speaker used, in cases where the matrix was systematically and frustratingly ambiguous. To address this question, we used a display like the one in Figure \ref{fig:levels-oddman}, top:

\begin{equation}
\left[
    \begin{array}{ccc}
      1 & 1 & 0 \\
      1 & 0 & 1\\
      0 & 1 & 1
    \end{array}
  \right]
\end{equation}

\noindent Although every feature was ambiguous, a potential equilibrium would be the use of a particular feature to describe the target \emph{without} that feature. For example, here ``hat'' could refer to the face without a hat; ``glasses'' to the face without glasses; etc. But by and large, participants did not converge on this equilibrium and instead were content to choose between the two ambiguous referents.

A second condition examined whether participants would be more or less likely to abandon the signal if it were an unconventional signal rather than a word with conventional semantics. In this condition, we recolored the features of each object (e.g., the hat and glasses) so that each had its own unique color. Bob then communicated by showing a color patch corresponding to the matching feature. Contra our initial prediction, participants stuck \emph{more} closely to the match between color patches and particular features, choosing the ``odd man out'' at very low rates. This condition suggests that it may be a feature of reasoning in these signaling games (rather than of words per se) that keeps participants from abandoning the literal semantics of the particular signals the communicator uses.

In sum, these experiments suggest that evidence for level 1 inferences was robust across a variety of displays, for example in the new matrix types show in \exptrefrange{exp:levels-level}{exp:levels-twins}). But we saw very little evidence that, in a one-shot game of the sort studied here, we would see participants abandoning the literal semantics of the words that were used.


% \input{section-size}

% \input{section-sequences}

% \input{section-production}

\section{Model fits and model comparison}
\label{sec:modelcomp}

In the experiments reported above, we see strong evidence that participants are engaging in reasoning that goes beyond the simple semantic interpretation of messages. Instead, they appear to be making inferences about reference in context that have the character of pragmatic reasoning---considering inferential alternatives that a speaker could have said. In this section, we test the ability of the RSA model to describe human behavior in these experiments.


\subsection{Model comparison methods}

For each experiment in the second and third sequences (\exptrefrange{exp:prior-baserate}{exp:levels-oddman}), we compared predictions of the RSA model to participant data. As in \citeA{frank2012}, for each experiment and experimental condition, we compared the proportion of participants choosing each different target to the model's predictions about that target. This procedure yielded between 4 and 10 datapoints per experiment.

We used an implementation of the RSA model provided by a new package for the R statistical computing platform: \texttt{rrrsa}. The package is available at \url{http://github.com/benpeloquin7/rrrsa} and installation instructions and comprehensive documentation are also available at that link.

\red{confidence intervals}.

\red{EPSILON: check details}.

\subsection{RSA models achieve globally good fit to experimental data}

\begin{figure}[t]
 \centering
 \includegraphics[width=6in]{../plots/model_basic.pdf}
 \caption{\label{fig:basic} Human data plotted against RSA model predictions for a recursive depth of 1, and $\alpha=1$. Each point shows proportion of choices for a single target object. Colors denote the pragmatic target (e.g., glasses), logically true object (e.g., hat and glasses), foil (e.g., no hat, no glasses). Vertical error bars are binomial confidence intervals; horizontal error bars are computed by resampling prior data and recomputing model predictions (see text). Black lines show the line of best fit.}
\end{figure}

In our first simulation, we used the exact version of the RSA model given in \citeA{frank2012}, with a recursive depth of 1 and $\alpha=1$. Results of this simulation are given in Figure \ref{fig:basic}. The RSA model was correlated with human judgments ($r_{all} = .86$), and this correlation persisted even when removing those points predicted to be 0 or 1 ($r_{no 0/1} = .68$).\footnote{For \exptref{exp:prior-salience}---and to a lesser extent, for \exptref{exp:prior-lang}---we saw a number of conditions in which model predictions had very high variance. This variance arises from variability in the prior on particular objects (since they are chosen very infrequently in the prior condition, they show high numerical instability).}

Nevertheless, there were a number of experimental conditions for which this parameter setting did not yield good predictions. In \exptrefrange{exp:prior-baserate}{exp:levels-level}, there appears to be a trend in which the model overpredicts for options that are judged to be lower probability, and underpredicts for those options judged more likely by participants. (This trend manifests itself as a cluster of predictions that are too close to the vertical midline of $p=.5$). In order to explore this trend further, we next varied the recursive depth in the model. Intuitively, further recursion should strengthen pragmatic inferences.

\subsection{Deeper recursion improves model performance}

% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Wed Jul  6 10:15:12 2016
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
depth & $r_{all}$ & $r_{no~0/1}$ \\
  \hline
  0 & 0.74 & 0.14 \\
    1 & 0.86 & 0.68 \\
    2 & 0.93 & 0.86 \\
    3 & 0.95 & 0.90 \\
    4 & 0.95 & 0.91 \\
    5 & 0.95 & 0.91 \\
   \hline
\end{tabular}
\caption{\label{tab:corr-a1} Correlations of model and data on both the full dataset and the subset of conditions for which the model did not predict a probability of either 0 or 1.}
\end{table}

Table \ref{tab:corr-a1} shows the results of simulations at depths 0 -- 5. These results show two main findings. First, and critically, a single level of recursion dramatically improves performance over and above a flat (literal listener) model. This trend is especially pronounced for non-binary model predictions. Indeed, our experiments were designed to probe cases where a literal listener would make equal predictions for different objects but a pragmatic agent would differentiate between them. Thus, this result provides a (perhaps obvious, but still important) confirmation of our basic hypothesis, namely that participants reason pragmatically in our experiments.

\begin{figure}[t]
 \centering
 \includegraphics[width=6in]{../plots/model_depth.pdf}
 \caption{\label{fig:depths} Human data plotted against RSA model predictions for recursive depths 0 -- 2, and $\alpha=1$. Plotting conventions are as above.}
\end{figure}

Second, however, the simulations showed an unexpected finding: deeper levels of recursion correlated more highly with human judgments. In particular, even four levels of recursion improved fit numerically compared with three levels (especially for non-0/1 predicted values). Figure \ref{fig:depths} shows simulation results at depths 0 -- 1 (the middle row is identical to Figure \ref{fig:basic}); we do not plot depths 3 -- 5 because they are visually almost indistinguishable from depth 2 even though there are minor numerical differences in their correlation with participant data.

Recall, however, that we set the $\alpha$ parameter to 1 in these simulations . $\alpha$ controls the ''greediness'' of the model's choice rule, with higher values indicating a greater willingness to choose higher-probability options. In the next set of simulations, we let $\alpha$ vary.

\subsection{The $\alpha$ parameter trades off with recursive depth, limiting model depth identifiability}

\begin{figure}[t]
 \centering
 \includegraphics[width=5in]{../plots/alpha-fit.pdf}
 \caption{\label{fig:alpha-fit} Correlation between full human dataset and RSA models at different levels of $\alpha$. Colors show levels of recursive depth from 0--5.}
\end{figure}

% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Thu Jul  7 09:53:32 2016
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
depth & $\alpha_{best}$ & $r_{all}$ & $r_{no~0/1}$ \\
  \hline
  0 & 0.0 & 0.74 & 0.14 \\
    1 & 3.1 & 0.95 & 0.89 \\
    2 & 1.4 & 0.95 & 0.91 \\
    3 & 1.1 & 0.95 & 0.91 \\
    4 & 1.0 & 0.95 & 0.91 \\
    5 & 1.0 & 0.95 & 0.91 \\
   \hline
\end{tabular}
\caption{\label{tab:corrs-fita} Correlations of model and data (as above) with best-fitting $\alpha$ value at each depth.}
\end{table}

Figure \ref{fig:alpha-fit} shows the range of correlations with human data achieved at different levels of $\alpha$, across recursive depths; Table \ref{tab:corrs-fita} gives the highest correlation and corresponding $\alpha$ level. Two findings become apparent. First, at the highest level, although numerical correlations do vary across $\alpha$ levels, with $\alpha > 1$ the range of correlations is quite restricted across all depths. Thus, the performance of the model is relatively insensitive to this parameter.

Nevertheless, a close examination of Table \ref{tab:corrs-fita} shows that values at depth 2 and especially depth 1 are noticeably higher than in Table \ref{tab:corrs} where $\alpha=1$. In fact, by setting $\alpha=3.1$, a model with depth 1 still achieves just about the same level of fit to data as a model with depth 4 or 5. This finding suggests that $\alpha$ and depth trade off against one another in most of the experiments that we conducted.

To understand this finding, consider the worked example above (used in many of our experiments):

\begin{equation}
\left[
    \begin{array}{ccc}
      0 & 0 & 1 \\
      0 & 1 & 1\\
    \end{array}
  \right]
\end{equation}

\noindent In this case, recursive depth 1 at $\alpha=1$ produces:

\begin{equation}
\left[
    \begin{array}{ccc}
      0 & 0 & 1 \\
      0 & .75 & .25\\
    \end{array}
  \right]
\end{equation}

\noindent But note that recursive depth 2 produces:

\begin{equation}
\left[
    \begin{array}{ccc}
      0 & 0 & 1 \\
      0 & .83 & .17\\
    \end{array}
  \right]
\end{equation}

\noindent which is identical to the same result at recursive depth 1 with \red{$\alpha = XYZ$}. But that is not always true. In principle, if a particular matrix is completely ambiguous at a particular recursive depth, then changing $\alpha$ will not affect performance. (A trivial example of this would be changing levels of $\alpha$ for a literal listener; clearly this manipulation would have no effect since by definition the literal listener assigns probability evenly to all alternatives).

\section{General Discussion}
\label{sec:discussion}

%
% We are well aware of the difficulties surrounding reasoning from a good fit alone \cite{roberts2000}. In a nutshell, any model must both show that it \emph{can} predict the data that actually occurred and \emph{cannot} predict the data that did not occur. The flexibility of the theory is thus of critical importance in understanding its performance. The RSA model as stated here and earlier contains a relatively small number of parameters, however: primarily $n$ (the depth of recursion) and $\alpha$, the greed parameter in the choice rule.


\subsection{Other work using RSA and variants}

Epistemic inferences \cite{goodman2013}

Affective \cite{kao2014}


Quantifiers \cite{franke2013}


Embedded implicature \cite{potts2015}

\subsection{Limitations}

Production


\newpage

\bibliographystyle{apacite}
\bibliography{pragmods}

\newpage


\end{document}


% \theappendix

% \input{section-equivalences}

% \input{section-matrix}
