
\section{General Methods}

\begin{figure}[t]
  \centering
  \includegraphics[width=4in]{figures/hatglasses.pdf}
  \caption{\label{fig:hg} An example stimulus item showing our canonical inferential context. The prompt in this case would be ``glasses,'' and the pragmatic target item would be the face with glasses but not a hat (the logical target item would be the face with a hat and glasses). In all experiments reported here, position and identity of all features is randomized across displays; the target was not always the face with glasses nor was it always positioned in the middle.}
\end{figure}

Our goal was to create a general method for measuring pragmatic inferences in simple reference games. Our taking-off point were previous studies by \citeA{frank2012} and \citeA{stiller2014}, in which simple feature-based displays allowed the measurement of pragmatic reasoning in grounded contexts. Following \citeA{stiller2014}, we created a set of materials with interchangeable features that could be used to create simple and transparent referential signaling games. In the experiments that follow we attempt to demonstrate that these signaling games provide a useful tool for measuring pragmatic reasoning. 


\subsection{Participants}

We converged quickly on a general standard of 50 independent participants per cell, based on the tradeoff between cost and the desired precision of the estimates on our measurements. With samples of N=50 participants, we could assume 95\% confidence intervals with width .24 at their widest; doubling the sample size to N=100 per cell would only reduce width to .18. While not every experiment reflects this precise standard due to idiosyncrasies of recruitment exclusion, we have tried to maintain approximately this standard throughout. 

All of the experiments described here were run on Amazon's Mechanical Turk crowdsourcing service, between Fall 2013 and Spring of 2015. In general, each experiment was run as an independent human intelligence task (HIT); a few were posted as multiple hits for convenience or due to experimenter error. In all cases, we remove duplicated workers from the samples, so that data in each experiment represent unique judgments by distinct participants. 

In addition to excluding duplicated participants, we also excluded participants who failed the manipulation checks (see below). Table \ref{tab:expts} gives details of participants for each experiment. 

\subsection{Stimuli}

We created a set of six base domains that had features that could easily be added independently: faces, boats, pizzas, sundaes, snowmen, and christmas trees. We created slightly different versions of each base so that they would appear to be unique (e.g., by varying the proportions or color tone of the face). We then were able to add features to each of these programmatically (with most experiments using two features but some using three). Faces were supplemented with hats, glasses, and mustaches; boats had motors, sails, and cabins; pizzas had olives, peppers, and mushrooms; sundaes had whipped cream, chocolate, and cherries on top; snowmen had mittens, hats, and scarves; and christmas trees had lights, ornaments, and stars on top.

\subsection{Procedure}

Participants viewed the experiment within a browser window. The first screen of the experiment presented a basic description of the paradigm and asked for informed consent. The second screen of the experiment presented the interlocutor, Bob (a cartoon picture of a man), and noted that he liked to do activities with the base item (e.g., visit friends or sail boats). In experiments with familiarization stimuli (e.g., \exptref{exp:prior-fam}), familiarization images were presented on this screen. 

The third screen was the key screen: it presented the experimental stimulus (a set of base items augmented with features, representing the signaling game of interest) at the top of the screen. In all experiments except for \exptref{exp:prelims-mc}, two manipulation check questions were asked directly below the display using text entry boxes (e.g. ``how many boats have cabins?''). Below this was the prompt, e.g. ``Bob can only use one word to tell you about which friend he visited. He says: {\it glasses}. Which friend do you think he visited?'' and below this was a set of radio buttons for the participant to indicate which of the three options they thought the speaker was referring to. A final screen asked participants for comments or feedback and asked about their impressions of what the study was about. 

Note that in the first set of experiments, we manipulate a number of these experimental choices, including the dependent variable, the use of the manipulation check, and the linguistic framing of Bob's utterance. Our description here reflects the defaults used in the majority of the experiments we report. 



% Minor stuff:

% Prelims measures has four items

% Size and sequence have no manipulation check 

%%% Local Variables: 
%%% TeX-master: "pragmods"
%%% End:
