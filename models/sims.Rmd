---
title: "Model Simulations"
author: "Mike Frank"
date: "August 28, 2015"
output: html_document
---

Fit vanilla RSA models to the data from prior and levels series experiments. 

## Preliminaries

```{r}
library(binom)
library(magrittr)
library(langcog)
rm(list=ls())
source("../analysis/useful_dplyr.R")
source("agents.R")
source("util.R")
source("matrices.R")

knitr::opts_chunk$set(fig.width=12, cache=TRUE,
                      warning=FALSE, message=FALSE)
library(dplyr, warn.conflicts = FALSE, quietly=TRUE)
library(tidyr, warn.conflicts = FALSE, quietly=TRUE)
```

Set up helper function to run model. 

```{r}
do.model <- function(matrix, 
                     model = "LSLS",
                     query_feature, 
                     query_target, 
                     prior = NULL, 
                     debug = FALSE) {
  
  mat <- eval(parse(text=as.character(matrix)))  
  mod <- eval(parse(text=paste(as.character(model), 
                               "(mat, prior = prior)", 
                               sep="")))
  
  if (debug) {
    print(model)
    print(matrix)
    print(prior)
    print(mod)
  }

  return(mod[as.character(query_feature), as.character(query_target)])
}
```

## Load data. 

Note: `levels_mod.csv` has the levels of the "levels" complex experiment manually modified, because while we are using terms like "target" here as an absolute reference, it was used as a relative reference in that experiment design. Meaning, "target" for level 0 was actually what we refer to here as "logical," and "target" for level 1 was "foil" here.

`prior_mod.csv` just has some levels renamed so they are terser and more informative.

```{r}
d.prior <- read.csv("data/prior_mod.csv") 
d.levels <- read.csv("data/levels_mod.csv")
```

Make sure that each experiment is tagged with its appropriate matrix. 

```{r}
d.raw <- bind_rows(d.prior, d.levels) %>%
  mutate(matrix = ifelse(expt == "color" | expt == "prior" | 
           expt == "lang" | expt == "baserate", "simple", expt))
```

split priors and inference, and make sure that each inference is tagged with its prior. Some of this has to be manual AFAIK.

```{r}
prior <- filter(d.raw, question == "prior") %>%
  mutate(prior = str_c(cond, "-", expt)) %>%
  select(-cond, -expt, -matrix, -question)

inference <- filter(d.raw, question == "inference") %>%
  mutate(prior = str_c(cond, "-", expt),
         query = "glasses")

inference$prior[inference$expt == "complex"] <- "0-complex"
inference$prior[inference$expt == "oddman"] <- "prior-oddman"
inference$prior[inference$expt == "twins"] <- "prior-twins"
inference$prior[inference$expt == "simple"] <- "prior-prior"
inference$prior[inference$prior == "none-color"] <- "prior-prior"

inference$query[inference$cond == "0" & inference$matrix == "simple"] <- "hat"
inference$query[inference$cond == "0" & inference$matrix == "complex"] <- "hat"
inference$query[inference$cond == "1" & inference$matrix == "complex"] <- "mustache"
inference$query[inference$cond == "2" & inference$matrix == "complex"] <- "glasses"
inference$query[inference$cond == "twin" & inference$matrix == "twins"] <- "hat"
inference$query[inference$cond == "uniform" & inference$matrix == "twins"] <- "mustache"
```

Get CIs, etc. 

Critically, this is where we add $\epsilon$, a smoothing parameter on the prior. 

```{r}
inference %<>%
  select(-question) %>%
  gather(object, count, foil, logical, target) %>%
  mutate(count = ifelse(is.na(count), 
                        0, count)) %>%
  group_by(expt, cond) %>%
  mutate(p = count / sum(count), 
         n = sum(count), 
         cil = binom.bayes(count, sum(count))$lower,
         cih = binom.bayes(count, sum(count))$upper) 

eps <- 0
prior %<>% 
  mutate(normalizer = foil + target + logical + 3*eps,
         foil = (foil + eps) / normalizer, 
         target = (target + eps) / normalizer,
         logical = (logical + eps) / normalizer) %>% 
  select(foil, logical, target, prior)
```

Now run models by merging in priors. 

```{r}
## add prior on every row
d <- left_join(inference, prior)            
write.csv(d, "data/models.csv", row.names=FALSE)
  
models <- factor(c("L0","L1","L2","L3", "L4","L5"))
md <- data.frame()

for (i in 1:length(models)) {
  md.new <- d %>%  
    group_by(expt, cond, object) %>%
    mutate(model = as.character(models[i]),
           prediction = do.model(matrix = matrix, 
                                 model = model, 
                                 query_feature = query, 
                                 query_target = object,
                                 prior = c(foil, 
                                           target, 
                                           logical))) 
  md <- bind_rows(md, md.new)
}

md$prior <- "prior"

for (i in 1:length(models)) {
  md.new <- d %>%  
    group_by(expt, cond, object) %>%
    mutate(model = as.character(models[i]),
           prediction = do.model(matrix = matrix, 
                                 model = model, 
                                 query_feature = query, 
                                 query_target = object,
                                 prior = c(.333, .333, .333)))
  md.new$prior <- "uniform"
  md <- bind_rows(md, md.new)
}

```

Investigate/debug sample model runs

```{r}
this_row <- d[d$expt == "color" & d$object == "target" & d$cond == "logical",]
this_row %>% data.frame
with(this_row, 
     do.model(matrix = matrix, 
              model = "L1", 
              query_feature = query, 
              query_target = object,
              prior = c(foil, target, logical),
              debug=TRUE))
```

## Plots

First, all points, with no prior split points.

```{r}
ggplot(filter(md, prior == "prior",
              model %in% c("L0","L1","L2")), 
       aes(x = prediction, y = p, col = expt, pch = object)) + 
  geom_pointrange(aes(ymin = cil, ymax = cih)) + 
  # geom_text(aes(label = cond, x = prediction + .02), size=3, hjust=0) +
  xlim(c(0,1)) + ylim(c(0,1)) + 
  facet_wrap(~model) + 
  ylab("Proportion choosing target") + 
  xlab("Model Predictions") + 
  geom_smooth(method="lm", aes(group=1)) + 
  geom_abline(slope = 1, intercept = 0, lty=2)
```

Now show the difference between prior and no prior.

```{r}
ggplot(md, aes(x = prediction, y = p, col = expt, pch = object)) + 
  geom_pointrange(aes(ymin = cil, ymax = cih)) + 
  geom_text(aes(label = cond, x = prediction + .02), size=3, hjust=0) +
  xlim(c(0,1)) + ylim(c(0,1)) + 
  facet_grid(prior~model) + 
  ylab("Proportion choosing target") + 
  xlab("Model Predictions") + 
  geom_smooth(method="lm", aes(group=1)) + 
  geom_abline(slope = 1, intercept = 0, lty=2)
```

Plot just those with non-0/1 values.

```{r}
ggplot(filter(md, prediction > 0 & prediction < 1),  
       aes(x = prediction, y = p, col = expt, pch = object)) + 
  geom_pointrange(aes(ymin = cil, ymax = cih)) + 
  geom_text(aes(label = cond, x = prediction + .02), size=3, hjust=0) +
  xlim(c(0,1)) + ylim(c(0,1)) + 
  facet_grid(prior~model) + 
  ylab("Proportion choosing target") + 
  xlab("Model Predictions") + 
  geom_smooth(method="lm", aes(group=1)) + 
  geom_abline(slope = 1, intercept = 0, lty=2)
```

Stats.

```{r}
md %>% 
  group_by(prior, model) %>%
  summarise(r_pearson = cor.test(p, prediction, method = "pearson")$estimate,
            r_spearman = cor.test(p, prediction, method = "spearman")$estimate,
            MSE = mean((prediction-p)^2))

md %>% 
  filter(prediction > 0 & prediction < 1) %>%
  group_by(prior, model) %>%
  summarise(r_pearson = cor.test(p, prediction, method = "pearson")$estimate,
            r_spearman = cor.test(p, prediction, method = "spearman")$estimate,
            MSE = mean((prediction-p)^2))

```

Plots by experiment.

```{r}
ggplot(filter(md, prior == "prior"), 
       aes(x = prediction, y = p, col = expt, pch = object)) + 
  geom_pointrange(aes(ymin = cil, ymax = cih)) + 
  xlim(c(0,1)) + ylim(c(0,1)) + 
  facet_grid(expt~model) + 
  ylab("Proportion choosing target") + 
  xlab("Model Predictions") + 
  geom_smooth(method="lm", aes(group=1)) + 
  geom_abline(slope = 1, intercept = 0, lty=2)
```

## Simulate forward from the model 

Strategy here is to figure out how different model predictions are in this matrix set anyway. 

```{r}
models <- md %>%
  mutate(modelcond = interaction(model, prior)) %>%
  select(cond, expt, matrix, object, prediction, modelcond) %>%
  spread(modelcond, prediction)

ggcorplot(models)
```

With no prior. 

```{r}
models.np <- md %>%
  filter(prior == "prior") %>%
  select(cond, expt, matrix, object, prediction, model) %>%
  spread(model, prediction)

quartz()
ggcorplot(filter(models.np, L0 > 0 & L0 < 1))
```


Now with the removal of 0/1 predictions. This makes much more of a difference.

```{r}
ggcorplot(filter(models, L0.uniform > 0 & L0.uniform < 1))
```
